import pickle  
import torch  
import numpy as np  
import random  
from torch_geometric.loader import DataLoader  

def load_and_scale_data(file_path):  
    with open(file_path, 'rb') as f:  
        dataset = pickle.load(f)  
    
    mean = torch.mean(torch.cat([data['x'] for data in dataset]), dim=0)  
    std = torch.std(torch.cat([data['x'] for data in dataset]), dim=0)  
    for data in dataset:  
        data['x'] = (data['x'] - mean) / std  
    
    return dataset  

dataset = load_and_scale_data('dataset.pkl')  
print(len(dataset))  

y_1 = [data.y[0] for data in dataset if data.y[0] == 1]  
y_0 = [data.y[0] for data in dataset if data.y[0] == 0]  

num_1 = len(y_1)  
num_0 = len(y_0)  

idx_0 = np.random.choice(range(num_0), size=num_1, replace=False)  
data_0 = [dataset[i] for i in idx_0]  

data_resampled = [dataset[i] for i in range(len(dataset))  
                  if dataset[i].y[0] in (y_1 + [data_0[j].y[0]  
                                                for j in range(len(data_0))])]  

print("Resampled dataset shape:", np.unique([data.y[0] for data in data_resampled], return_counts=True))  

random.shuffle(data_resampled)  

train_ratio = 0.7  
val_ratio = 0.15  
test_ratio = 0.15 

total_size = len(data_resampled)  
train_size = int(total_size * train_ratio)  
val_size = int(total_size * val_ratio)  
test_size = int(total_size * test_ratio)  

train_dataset = data_resampled[:train_size]  
val_dataset = data_resampled[train_size : train_size + val_size]  
test_dataset = data_resampled[train_size + val_size :]  
