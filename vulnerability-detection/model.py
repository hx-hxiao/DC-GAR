import torch
import random
from torch.nn import Linear
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.nn import global_mean_pool
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, classification_report


def perturb_node_features(x, noise_level=0.01):

    if isinstance(x, np.ndarray):
        x = torch.tensor(x)

    x = x + noise_level * torch.randn_like(x)
    return x


def mask_node_features(x, mask_rate=0.1):

    num_nodes, num_features = x.size()
    mask = np.random.binomial(1, mask_rate, (num_nodes, num_features))
    mask = torch.FloatTensor(mask).to(x.device)
    x = x * (1 - mask)
    return x


class GCN(torch.nn.Module):
    def __init__(self, hidden_channels):
        super(GCN, self).__init__()
        self.conv1 = GCNConv(128, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, 32)
        self.conv3 = ChebConv(128, hidden_channels, K=2)
        self.conv4 = ChebConv(hidden_channels, 32, K=2)
        self.lin = Linear(32, 2)
        self.dropout_rate = 0.5

    def forward(self, x, edge_index, batch):
        x1 = perturb_node_features(x, noise_level=0.01)
        x1 = self.conv1(x1, edge_index).relu()
        x1 = F.dropout(x1, p=self.dropout_rate, training=self.training)
        x1 = self.conv2(x1, edge_index)

        x2 = mask_node_features(x, mask_rate=0.1)
        x2 = self.conv1(x, edge_index).relu()
        x2 = F.dropout(x2, p=self.dropout_rate, training=self.training)
        x2 = self.conv2(x2, edge_index)

        x = x1 + x2
        x = F.dropout(x, p=self.dropout_rate, training=self.training)
        x = global_mean_pool(x, batch)  
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin(x)
        return x


model = GCN(hidden_channels=64).to(device)
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)
exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=200, threshold=1e-8, min_lr=1e-8)


def train():
    model.train()
    total_loss = 0
    num_batches = 0

    for data in train_loader: 
        data = data.to(device)
        out = model(data.x, data.edge_index, data.batch)  
        loss = criterion(out, data.y) 
        loss.backward()  
        optimizer.step() 
        optimizer.zero_grad() 

        total_loss += loss.item()
        num_batches += 1

    loss = total_loss / num_batches
    print(f'Loss: {loss:.4f}')
    return loss


def test(loader):
    model.eval()

    total_loss = 0
    total_acc = 0
    total_f1 = 0
    total_precision = 0
    total_recall = 0
    num_batches = 0

    for data in loader:  # Iterate in batches over the training/test dataset.
        data = data.to(device)
        out = model(data.x, data.edge_index, data.batch)

        loss = criterion(out, data.y) 
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()  

        pred = out.argmax(dim=1) 
        acc = accuracy_score(data.y.cpu(), pred.cpu())
        f1 = f1_score(data.y.cpu(), pred.cpu(), average='macro')
        precision = precision_score(data.y.cpu(), pred.cpu(), average='macro')
        recall = recall_score(data.y.cpu(), pred.cpu(), average='macro')
        total_loss += loss.item()

        total_acc += acc
        total_precision += precision
        total_recall += recall
        total_f1 += f1
        num_batches += 1

    acc = total_acc / num_batches
    f1 = total_f1 / num_batches
    precision = total_precision / num_batches
    recall = total_recall / num_batches
    loss = total_loss / num_batches

    if loader == test_loader:
        print(f'Loss: {loss:.4f}')
    print(f'Acc: {acc:.4f}, Precision:{precision:.4f}, Recall:{recall:.4f}, F1: {f1:.4f}')
    return acc, precision, recall, f1


total_loss = 0

total_train_acc = 0
total_train_f1 = 0
total_train_precision = 0
total_train_recell = 0

total_test_acc = 0
total_test_f1 = 0

best_train_acc = 0
best_train_f1 = 0
best_test_acc = 0
best_test_f1 = 0

number = 2000
save_interval = 100

with open('training_results.txt', 'w') as f:
    f.write("Epoch,Train Acc,Train F1,Train Precision,Train Recall,Test Acc,Test F1,Test Precision,Test Recall\n")

for epoch in range(1, number):
    print(f'Epoch:{epoch:03d}')
    print("train:")
    loss = train()
    total_loss += loss

    acc_train, train_precision, train_recall, f1_train = test(train_loader)
    total_train_acc += acc_train
    total_train_f1 += f1_train
    total_train_precision += train_precision
    total_train_recell += train_recall

    if acc_train > best_train_acc:
        best_train_acc = acc_train
        torch.save(model.state_dict(), 'best_train_model.pth')
    if f1_train > best_train_f1:
        best_train_f1 = f1_train
    print(f"New best train acc: {best_train_acc:.4f}, New best train f1: {best_train_f1:.4f}")

    print("test:")
    acc_test, test_precision, test_recall, f1_test = test(test_loader)
    total_test_acc += acc_test
    total_test_f1 += f1_test
    if acc_test > best_test_acc:
        best_test_acc = acc_test
        torch.save(model.state_dict(), 'best_test_model.pth')
    if f1_test > best_test_f1:
        best_test_f1 = f1_test
    print(f"New best test acc: {best_test_acc:.4f}, New best test f1: {best_test_f1:.4f}")
    print("----------------------------------------------------------------------")

    if epoch % save_interval == 0:
        with open('training_results.txt', 'a') as f:
            f.write(
                f"{epoch},{acc_train:.4f},{f1_train:.4f},{train_precision:.4f},{train_recall:.4f},{acc_test:.4f},{f1_test:.4f},{test_precision:.4f},{test_recall:.4f}\n")
        print(f"Saved results for epoch {epoch}")


avg_loss = total_loss / number
avg_train_acc = total_train_acc / number
avg_train_f1 = total_train_f1 / number
avg_test_acc = total_test_acc / number
avg_test_f1 = total_test_f1 /number

print(f'avg_loss: {avg_loss:.4f}, avg_train_acc: {avg_train_acc:.4f}, avg_train_f1: {avg_train_f1:.4f}',
      f'avg_test_acc: {avg_test_acc:.4f}, avg_test_f1: {avg_test_f1:.4f}')


end_time = time.time()
run_time = end_time - start_time  
print(f"Time: {run_time:.2f} s")

